user nginx;
worker_processes auto; # Adjust based on your server's cores

error_log /var/log/nginx/error.log warn;
pid       /var/run/nginx.pid;

events {
    worker_connections 1024; # Adjust as needed
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    tcp_nopush      on;
    tcp_nodelay     on;
    keepalive_timeout  65;
    types_hash_max_size 2048;

    # Gzip Compression
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_buffers 16 8k;
    gzip_http_version 1.1;
    gzip_min_length 256;
    gzip_types text/plain text/css application/json application/javascript application/x-javascript text/xml application/xml application/xml+rss text/javascript image/svg+xml;

    # Rate Limiting Zone (adjust as needed)
    # Limit to 10 requests per second per IP, with a burst of 20
    limit_req_zone $binary_remote_addr zone=mylimit:10m rate=10r/s;

    # Cache Path (adjust path and size as needed)
    # Stored in a directory inside the Nginx container
    proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m use_temp_path=off;
    proxy_cache_key "$scheme$request_method$host$request_uri";

    # Upstream server groups
    upstream order_backend {
        # Round Robin (default) - Nginx will distribute load evenly
        # Assumes 'order' service scales to multiple instances (as per your docker-compose)
        server order:4000;
        # Add more 'server order:XXXX' lines if you have more static replicas not managed by docker swarm mode's ingress
        # For health checks:
        # server order:4000 max_fails=3 fail_timeout=30s;
    }

    upstream reco_backend {
        least_conn; # Sends request to the server with the fewest active connections
        server reco:5000;
        # For health checks:
        # server reco:5000 max_fails=3 fail_timeout=30s;
    }

    upstream inventory_backend {
        ip_hash; # Ensures a particular client is always sent to the same server
        server inventory:8000;
        # For health checks:
        # server inventory:8000 max_fails=3 fail_timeout=30s;
    }

    # HTTP Server - Redirect all HTTP to HTTPS
    server {
        listen 80;
        server_name localhost yourdomain.com; # Replace with your actual domain if you have one

        location / {
            return 301 https://$host$request_uri;
        }

        location /stub_status {
            stub_status;
            allow all;
        }

    }

    # HTTPS Server
    server {
        listen 443 ssl http2;
        server_name localhost yourdomain.com; # Replace with your actual domain

        # SSL Configuration
        ssl_certificate /etc/nginx/ssl/nginx.crt;
        ssl_certificate_key /etc/nginx/ssl/nginx.key;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_prefer_server_ciphers on;
        ssl_ciphers 'ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384';
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;
        ssl_session_tickets off;
        # ssl_stapling on; # Requires resolver
        # ssl_stapling_verify on; # Requires resolver
        # resolver 8.8.8.8 8.8.4.4 valid=300s; # Example resolver, needed for stapling

        # Security Headers
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload" always;
        add_header Referrer-Policy "strict-origin-when-cross-origin" always;
        # add_header Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline';" always; # Adjust CSP as needed

        # Default Rate Limiting (apply to all locations, or specific ones)
        # limit_req zone=mylimit burst=20 nodelay;

        # Proxy common settings
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_buffering on;

        # Location for the simple UI
        location /ui/ {
            alias /usr/share/nginx/html/; # Path inside the Nginx container where interface.html will be
            index interface.html;
            try_files $uri $uri/ /interface.html; # Fallback for single-page app like routing
        }

        location /api/orders/ {
            proxy_pass http://order_backend/; # Note the trailing slash
            # Optional: We can add specific rate limit or caching for this location
            # limit_req zone=mylimit burst=10 nodelay;
        }

        location /api/reco/ {
            proxy_pass http://reco_backend/;
            proxy_cache my_cache; # Enable caching for this location
            proxy_cache_valid 200 302 10m;    # Cache 200 and 302 responses for 10 minutes
            proxy_cache_valid 404      1m;    # Cache 404 responses for 1 minute
            add_header X-Proxy-Cache $upstream_cache_status; # To see if cache was HIT/MISS/EXPIRED
        }

        location /api/inventory/ {
            proxy_pass http://inventory_backend/;
            proxy_cache my_cache;
            proxy_cache_valid 200 302 5m;
            proxy_cache_valid 404      1m;
            add_header X-Proxy-Cache $upstream_cache_status;
        }

        # Health check endpoint for upstreams (optional, more advanced)
        # location /health {
        #     access_log off;
        #     return 200 "OK";
        # }

        # If we use active health checks in upstream blocks (commercial Nginx or Nginx Plus feature,
        # or via third-party modules for open source Nginx), we configure them there.
        # For open source Nginx, the 'max_fails' and 'fail_timeout' in the upstream server directive
        # provide passive health checks.
    }
}